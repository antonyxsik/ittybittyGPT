{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My transformer notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import unicodedata\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from jaxtyping import Int, Float\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import transformers\n",
    "import transformer_lens\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if(torch.cuda.is_available() == True):\n",
    "    print(torch.cuda.device_count())\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python_3_11\\Lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "tinystorydata = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary auto-reload for development on local machine\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class GPTConfig:\n",
    "    \"\"\"Here we configure set up the dimensions of\n",
    "    our model. Defaults dimensions come from gpt-2 model\"\"\"\n",
    "    d_model: int = 192 #\n",
    "    d_vocab: int = 50257 # defines the number of different tokens that can be represented as inputs (vocabulary size)\n",
    "    n_context: int = 1024 # maximum sequence length (context window size)\n",
    "    n_layer: int = 3 # number of hidden layers\n",
    "    n_head: int = 3 # number of attenton heads \n",
    "\n",
    "    # make sure that model dimension is divisible by number of heads\n",
    "    @property\n",
    "    def d_head(self):\n",
    "        assert self.d_model % self.n_head == 0, f\"'{self.d_model = }' must be divisible by '{self.n_head = }': {self.d_model} % {self.n_head} == {self.d_model % self.n_head}\"\n",
    "        return self.d_model // self.n_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        # store dimensions\n",
    "        self.n_head: int = config.n_head\n",
    "        self.d_model: int = config.d_model\n",
    "        self.n_context: int = config.n_context\n",
    "\n",
    "        # concatenating the outputs of the heads should give us d_model, but this check is done in GPTConfig\n",
    "        self.d_head: int = config.d_head\n",
    "\n",
    "        # coefficient for scaling the dot product of the query and key in the attention calculation\n",
    "        self.sqrt_dim: float = 1.0 / math.sqrt(self.d_head)\n",
    "\n",
    "        # key, query, value projections\n",
    "        self.W_K: nn.Module = nn.Linear(self.d_model, self.d_head)\n",
    "        self.W_Q: nn.Module = nn.Linear(self.d_model, self.d_head)\n",
    "        self.W_V: nn.Module = nn.Linear(self.d_model, self.d_head)\n",
    "\n",
    "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "        # `register_buffer` means it's not a trainable parameter\n",
    "        self.register_buffer(\n",
    "            \"causal_mask\", \n",
    "            torch.tril(\n",
    "                torch.ones(config.n_context, config.n_context)\n",
    "            )\n",
    "            .view(1, 1, config.n_context, config.n_context)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Float[torch.Tensor, \"batch n_ctx d_model\"]) -> Float[torch.Tensor, \"batch n_ctx d_head\"]:\n",
    "        assert x.ndim == 3, str(x.shape)\n",
    "        B, n_ctx, d_model = x.shape # batch size, sequence length, embedding dimensionality (d_model)\n",
    "        assert d_model == self.d_model, str(x.shape)\n",
    "        # assert n_ctx == self.n_context, str(x.shape)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q: Float[torch.Tensor, \"batch n_ctx d_head\"] = self.W_Q(x)\n",
    "        k: Float[torch.Tensor, \"batch n_ctx d_head\"] = self.W_K(x)\n",
    "        v: Float[torch.Tensor, \"batch n_ctx d_head\"] = self.W_V(x)\n",
    "\n",
    "        # self-attention\n",
    "        # (B, n_ctx, d_h) x (B, d_h, n_ctx) -> (B, n_ctx, n_ctx)\n",
    "        att = (q @ k.transpose(-2, -1)) * self.sqrt_dim\n",
    "        \n",
    "        # autoregressive (causal) masking\n",
    "        att = att.masked_fill(\n",
    "            self.causal_mask[:,:n_ctx,:n_ctx] == 0, \n",
    "            float('-inf'),\n",
    "        )\n",
    "\n",
    "        # softmax\n",
    "        att = F.softmax(att, dim=-1)\n",
    "\n",
    "        # apply the self-attention to the values\n",
    "        # (B, n_ctx, n_ctx) x (B, n_ctx, d_h) -> (B, n_ctx, d_h)\n",
    "        output = att @ v\n",
    "        return output.view(B, n_ctx, self.d_head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionHead(\n",
      "  (W_K): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (W_Q): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (W_V): Linear(in_features=64, out_features=16, bias=True)\n",
      ")\n",
      "cfg.d_head = 16\n",
      "x.shape = torch.Size([1, 128, 64])\n",
      "A(x).shape = torch.Size([1, 128, 16])\n"
     ]
    }
   ],
   "source": [
    "cfg: GPTConfig = GPTConfig(\n",
    "\tn_context=128,\n",
    "\td_model=64,\n",
    "\tn_head=4,\n",
    ")\n",
    "A: AttentionHead = AttentionHead(cfg)\n",
    "print(A)\n",
    "\n",
    "x = torch.randn(1, cfg.n_context, cfg.d_model)\n",
    "print(f\"{cfg.d_head = }\")\n",
    "print(f\"{x.shape = }\")\n",
    "print(f\"{A(x).shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(A.causal_mask[0, 0].cpu().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "\tdef __init__(self, config: GPTConfig):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.n_head: int = config.n_head\n",
    "\t\tself.d_head: int = config.d_model // config.n_head\n",
    "\t\tself.d_model: int = config.d_model\n",
    "\n",
    "\t\t# attention heads\n",
    "\t\tself.attention_heads: nn.ModuleList = nn.ModuleList([\n",
    "\t\t\tAttentionHead(config) \n",
    "\t\t\tfor _ in range(self.n_head)\n",
    "\t\t])\n",
    "\n",
    "\t\t# output projection\n",
    "\t\tself.W_O: nn.Module = nn.Linear(self.d_model, self.d_model)\n",
    "\n",
    "\n",
    "\tdef forward(self, x: Float[torch.Tensor, \"batch n_ctx d_model\"]) -> Float[torch.Tensor, \"batch n_ctx d_model\"]:\n",
    "\t\tassert x.ndim == 3, str(x.shape)\n",
    "\t\t# apply all attention heads and concatenate their outputs\n",
    "\t\t# note: in reality, you would do this all in one tensor\n",
    "\t\t# we split the attention heads up to make it easier to understand\n",
    "\t\tatt = torch.cat(\n",
    "\t\t\t[\n",
    "\t\t\t\thead(x) \n",
    "\t\t\t\tfor head in self.attention_heads\n",
    "\t\t\t],\n",
    "\t\t\tdim=-1,\n",
    "\t\t)\n",
    "\t\tassert len(att.shape) == 3, str(att.shape)\n",
    "\n",
    "\t\t# output projection\n",
    "\t\t# (B, n_ctx, d_head * n_head) -> (B, n_ctx, d_model)\n",
    "\t\toutput = self.W_O(att)\n",
    "\t\tassert output.shape == x.shape, str(output.shape)\n",
    "\t\treturn output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\tdef __init__(self, config: GPTConfig):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t# layernorm, attention, another layernorm, mlp\n",
    "\t\tself.ln_1: nn.Module = nn.LayerNorm(config.d_model)\n",
    "\t\tself.attention: nn.Module = MultiHeadedAttention(config)\n",
    "\t\tself.ln_2: nn.Module = nn.LayerNorm(config.d_model)\n",
    "\t\tself.mlp: nn.Module = nn.Sequential(\n",
    "\t\t\tnn.Linear(config.d_model, 4 * config.d_model),\n",
    "\t\t\tnn.GELU(),\n",
    "\t\t\tnn.Linear(4 * config.d_model, config.d_model),\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x: Float[torch.Tensor, \"batch n_ctx d_model\"]) -> Float[torch.Tensor, \"batch n_ctx d_model\"]:\n",
    "\t\tassert x.ndim == 3, str(x.shape)\n",
    "\t\tx = x + self.attention(self.ln_1(x))\n",
    "\t\tassert x.ndim == 3, str(x.shape)\n",
    "\t\tx = x + self.mlp(self.ln_2(x))\n",
    "\t\tassert x.ndim == 3, str(x.shape)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "\tdef __init__(self, config: GPTConfig, tokenizer: transformers.PreTrainedTokenizer):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.config: GPTConfig = config\n",
    "\t\tself.tokenizer: transformers.PreTrainedTokenizer = tokenizer\n",
    "\t\tassert config.d_vocab >= tokenizer.vocab_size\n",
    "\n",
    "\t\t# token and positional embeddings\n",
    "\t\tself.token_embeddings: nn.Module = nn.Embedding(config.d_vocab, config.d_model)\n",
    "\t\tself.positional_embeddings: nn.Module = nn.Embedding(config.n_context, config.d_model)\n",
    "\n",
    "\t\t# transformer\n",
    "\t\tself.transformer_blocks: nn.ModuleList = nn.ModuleList([\n",
    "\t\t\tTransformerBlock(config) \n",
    "\t\t\tfor _ in range(config.n_layer)\n",
    "\t\t])\n",
    "\n",
    "\t\t# language model head\n",
    "\t\tself.ln_f: nn.Module = nn.LayerNorm(config.d_model)\n",
    "\t\tself.lm_head: nn.Module = nn.Linear(config.d_model, config.d_vocab, bias=False)\n",
    "\n",
    "\tdef forward(\n",
    "\t\t\tself, \n",
    "\t\t\tx: Int[torch.Tensor, \"batch n_ctx\"],\n",
    "\t\t\ttargets: Int[torch.Tensor, \"batch n_ctx\"]|None = None,\n",
    "\t\t) -> tuple:\n",
    "\t\t\"\"\"returns a tuple of (logits, loss) where loss=None if targets is None\"\"\"\n",
    "\t\tassert x.ndim == 2, str(x.shape)\n",
    "\n",
    "\t\t# calculate token and positional embeddings and sum them\n",
    "\t\tx_res = self.token_embeddings(x) + self.positional_embeddings(torch.arange(x.size(1), device=x.device))\n",
    "\n",
    "\t\tassert x_res.ndim == 3, str(x.shape)\n",
    "\n",
    "\t\t# transformer blocks\n",
    "\t\tfor i, block in enumerate(self.transformer_blocks):\n",
    "\t\t\tx_res = block(x_res)\n",
    "\n",
    "\t\t# language model head\n",
    "\t\tlogits: Float[torch.Tensor, \"batch n_ctx d_vocab\"] = self.lm_head(self.ln_f(x_res))\n",
    "\n",
    "\t\tloss = None\n",
    "\t\tif targets is not None:\n",
    "\t\t\tloss = F.cross_entropy(\n",
    "\t\t\t\tlogits.transpose(1, 2),\n",
    "\t\t\t\ttargets,\n",
    "\t\t\t\tignore_index=-1,\n",
    "\t\t\t)\n",
    "\n",
    "\t\treturn logits, loss\n",
    "\t\n",
    "\t@torch.no_grad()\n",
    "\tdef generate(\n",
    "\t\tself,\n",
    "\t\tprompt: str|list[int]|Int[torch.Tensor, \"* n_ctx\"],\n",
    "\t\tmax_new_tokens: int = 128,\n",
    "\t\ttemperature: float = 1.0,\n",
    "\t) -> str:\n",
    "\n",
    "\t\t# convert prompt to string and tensor versions\n",
    "\t\tprompt_str: str\n",
    "\t\tprompt_tensor: Int[torch.Tensor, \"1 n_ctx\"]\n",
    "\t\tif isinstance(prompt, str):\n",
    "\t\t\tprompt_str = prompt\n",
    "\t\t\tprompt_tensor = torch.tensor(self.tokenizer.encode(prompt_str), dtype=torch.long).unsqueeze(0) # add batch dim\n",
    "\t\telif isinstance(prompt, list):\n",
    "\t\t\tprompt_str = self.tokenizer.decode(prompt)\n",
    "\t\t\tprompt_tensor = torch.tensor(prompt, dtype=torch.long).unsqueeze(0) # add batch dim\n",
    "\t\telif isinstance(prompt, torch.Tensor):\n",
    "\t\t\tif prompt.ndim == 1:\n",
    "\t\t\t\tprompt = prompt.unsqueeze(0) # add batch dim\n",
    "\t\t\tassert prompt.ndim == 2\n",
    "\n",
    "\t\t\tprompt_str = self.tokenizer.decode(prompt[0].tolist())\n",
    "\t\t\tprompt_tensor = prompt\n",
    "\t\telse:\n",
    "\t\t\traise ValueError(f\"prompt must be a string, list of ints, or PyTorch tensor\")\n",
    "\t\t\n",
    "\t\t# check tensor dims\n",
    "\t\tassert isinstance(prompt_str, str) \n",
    "\t\tassert isinstance(prompt_tensor, torch.Tensor)\n",
    "\t\tassert prompt_tensor.ndim == 2 \n",
    "\t\tassert prompt_tensor.shape[0] == 1\n",
    "\n",
    "\t\t#  device\n",
    "\t\tprompt_tensor = prompt_tensor.to(self.device)\n",
    "\n",
    "\t\t# pad the prompt if necessary\n",
    "\t\tif prompt_tensor.shape[1] < self.config.n_context:\n",
    "\t\t\tprompt_tensor = F.pad(prompt_tensor, (0, self.config.n_context - prompt_tensor.shape[1]), value=self.tokenizer.pad_token_id)\n",
    "\n",
    "\t\tassert prompt_tensor.shape[1] == self.config.n_context\n",
    "\n",
    "\t\t# iterate until max_new_tokens is reached, or an end-of-sequence token is generated\n",
    "\t\tcompletions: list[int] = list()\n",
    "\t\tfor _ in range(max_new_tokens):\n",
    "\t\t\t# truncate sequence to block size\n",
    "\t\t\tprompt_len: int = prompt_tensor.shape[1]\n",
    "\t\t\tif prompt_len > self.config.n_context:\n",
    "\t\t\t\tprompt_tensor = prompt_tensor[:, -self.config.n_context:]\n",
    "\n",
    "\t\t\t# forward the model to get the logits for the index in the sequence\n",
    "\t\t\tlogits, _ = self(prompt_tensor)\n",
    "\n",
    "\t\t\t# pluck the logits at the final step and scale by desired temperature\n",
    "\t\t\tlogits = logits[:, -1, :] / temperature\n",
    "\n",
    "\t\t\t# apply softmax to convert logits to (normalized) probabilities\n",
    "\t\t\tprobs = F.softmax(logits, dim=-1)\n",
    "\n",
    "\t\t\t# sample from the distribution\n",
    "\t\t\tidx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "\t\t\t# append sampled index to the running sequence and continue\n",
    "\t\t\tidx = torch.cat((prompt_tensor, idx_next), dim=1)\n",
    "\n",
    "\t\t\t# append the token to the running completions\n",
    "\t\t\tcompletions.append(int(idx_next[0, 0]))\n",
    "\n",
    "\t\t\t# check if end of sequence token is generated\n",
    "\t\t\tif idx_next == self.tokenizer.eos_token_id:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\treturn self.tokenizer.decode(completions)\n",
    "\n",
    "\t@property\n",
    "\tdef n_params(self) -> int:\n",
    "\t\treturn sum(p.numel() for p in self.parameters())\n",
    "\t\n",
    "\t@property\n",
    "\tdef device(self) -> torch.device:\n",
    "\t\tdevice_set: set[torch.device] = set(p.device for p in self.parameters())\n",
    "\t\tassert len(device_set) == 1, device_set\n",
    "\t\treturn next(iter(device_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python_3_11\\Lib\\site-packages\\huggingface_hub\\repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "text_data_full = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\\n\\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\\n\\nBeep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.', 'One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \"Hi, I am Fin. Do you want to play?\" asked the little fish. The crab looked at Fin and said, \"No, I don\\'t want to play. I am cold and I don\\'t feel fine.\"\\n\\nFin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \"Please, sun, help my new friend feel fine and not freeze!\"\\n\\nThe sun heard Fin\\'s call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, \"Thank you, little fish, for making me feel fine. I don\\'t feel like I will freeze now. Let\\'s play together!\" And so, Fin and the crab played and became good friends.']}\n"
     ]
    }
   ],
   "source": [
    "text_data = text_data_full[\"train\"]\n",
    "print(text_data[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = \"\\n\\n\".join(text_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = text_data[:9601866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "\tdef __init__(\n",
    "\t\t\tself, \n",
    "\t\t\ttext: str, \n",
    "\t\t\ttokenizer: transformers.PreTrainedTokenizer,\n",
    "\t\t\tn_context: int,\n",
    "\t\t\tensure_n_context_match: bool = True,\n",
    "\t\t):\n",
    "\t\t# add 1 to n_context to account for the target token\n",
    "\t\tn_context += 1\n",
    "\n",
    "\t\t# tokenize the text\n",
    "\t\ttokenized_text: list[int] = tokenizer.encode(text)\n",
    "\t\tself.total_tokens: int = len(tokenized_text)\n",
    "\n",
    "\t\t# trim the last tokens to make sure the length is a multiple of n_context\n",
    "\t\tif ensure_n_context_match:\n",
    "\t\t\ttokenized_text = tokenized_text[:-(len(tokenized_text) % n_context)]\n",
    "\t\t\tself.total_tokens = len(tokenized_text)\n",
    "\n",
    "\t\t# split the text into examples of length n_context\n",
    "\t\t# this means that text will often start in the middle of a sentence\n",
    "\t\t# in reality, we might want to do this a bit smarter\n",
    "\t\tself.examples: list[list[int]] = [\n",
    "\t\t\ttokenized_text[i:i+n_context] \n",
    "\t\t\tfor i in range(0, len(tokenized_text), n_context)\n",
    "\t\t]\n",
    "\n",
    "\tdef __len__(self) -> int:\n",
    "\t\treturn len(self.examples)\n",
    "\t\n",
    "\tdef __getitem__(self, i: int) -> Float[torch.Tensor, \"n_ctx\"]:\n",
    "\t\treturn torch.tensor(self.examples[i], dtype=torch.long)\n",
    "\t\n",
    "\tdef example_lengths(self) -> Counter[int]:\n",
    "\t\treturn Counter(len(ex) for ex in self.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "\tmodel: GPT,\n",
    "\ttext: str,\n",
    "\toptimizer: torch.optim.Optimizer,\n",
    "\tdevice: torch.device = (\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\tbatch_size: int = 8,\n",
    "\tmax_batches: int|None = None,\n",
    "\tprint_interval: int = 100,\n",
    "\tepochs: int = 1,\n",
    ") -> tuple[GPT, list[dict]]:\n",
    "\t\n",
    "\t# move model to device\n",
    "\tprint(f\"moving model to device: {device}\")\n",
    "\tmodel.to(device)\n",
    "\t\n",
    "\t# set up data\n",
    "\tprint(f\"setting up dataset from text of length {len(text)}\")\n",
    "\tdataset: TextDataset = TextDataset(\n",
    "\t\ttext=text, \n",
    "\t\ttokenizer=model.tokenizer, \n",
    "\t\tn_context=model.config.n_context,\n",
    "\t)\n",
    "\tprint(f\"\\tset up dataset with {len(dataset)} examples, example lengths: {dataset.example_lengths()}\")\n",
    "\n",
    "\tprint(f\"setting up dataloader from {len(dataset)} examples\")\n",
    "\tdataloader: DataLoader = DataLoader(\n",
    "\t\tdataset, \n",
    "\t\tbatch_size=batch_size, \n",
    "\t\tshuffle=True,\n",
    "\t)\n",
    "\tprint(f\"\\tset up dataloader with {len(dataloader)} batches of size {batch_size}\")\n",
    "\n",
    "\t# set up training loop\n",
    "\tprint(\"training...\")\n",
    "\ttraining_records: list[dict] = list()\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tprint(f\"Epoch {epoch + 1}/{epochs}\\n\")\n",
    "\t\ti: int; batch: Float[torch.Tensor, \"batch n_ctx\"]\n",
    "\t\tfor i, batch in tqdm.tqdm(\n",
    "\t\t\tenumerate(dataloader),\n",
    "\t\t\ttotal=len(dataloader),\n",
    "\t\t\tdesc=\"Training\",\n",
    "\t\t):\n",
    "\t\t\t# move batch to device\n",
    "\t\t\tbatch = batch.to(device)\n",
    "\t\t\t\n",
    "\t\t\t# break if we've reached the maximum number of batches\n",
    "\t\t\tif max_batches is not None and i > max_batches:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t\t# forward pass\n",
    "\t\t\tlogits, loss = model(\n",
    "\t\t\t\tbatch[:, :-1],\n",
    "\t\t\t\ttargets=batch[:, 1:], # the targets are just the input, offset by one\n",
    "\t\t\t)\n",
    "\n",
    "\t\t\t# backward pass\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# record progress\n",
    "\t\t\ttraining_records.append({\n",
    "\t\t\t\t\"batch\": i,\n",
    "\t\t\t\t\"loss\": loss.item(),\n",
    "\t\t\t})\n",
    "\n",
    "\t\t\tif i % print_interval == 0:\n",
    "\t\t\t\tprint(f\"Batch {i}, Loss: {loss.item()}\\n\")\n",
    "\n",
    "\treturn model, training_records\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZER.vocab_size = 50257\n",
      "MODEL.n_params = 32115712\n"
     ]
    }
   ],
   "source": [
    "# we want to ensure our vocab dimension is the same as the tokenizer's vocab size\n",
    "TOKENIZER: transformers.PreTrainedTokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "print(f\"{TOKENIZER.vocab_size = }\")\n",
    "\n",
    "# set up a config for a small model\n",
    "CONFIG: GPTConfig = GPTConfig(\n",
    "\td_model=256,\n",
    "\td_vocab=TOKENIZER.vocab_size,\n",
    "\tn_context=256,\n",
    "\tn_layer=8,\n",
    "\tn_head=8,\n",
    ")\n",
    "\n",
    "# initialize the model\n",
    "MODEL: GPT = GPT(CONFIG, TOKENIZER)\n",
    "print(f\"{MODEL.n_params = }\")\n",
    "\n",
    "# optimizer\n",
    "OPTIMIZER: torch.optim.Optimizer = torch.optim.AdamW(MODEL.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving model to device: cpu\n",
      "setting up dataset from text of length 9601866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2395874 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tset up dataset with 9322 examples, example lengths: Counter({257: 9322})\n",
      "setting up dataloader from 9322 examples\n",
      "\tset up dataloader with 292 batches of size 32\n",
      "training...\n",
      "Epoch 1/1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/292 [00:16<1:20:15, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 10.961676597595215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▍      | 101/292 [25:42<49:46, 15.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100, Loss: 6.375736236572266\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████▉   | 201/292 [50:36<22:20, 14.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 5.39183235168457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 292/292 [1:12:45<00:00, 14.95s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_TRAINED, training_history = train(\n",
    "\tmodel=MODEL,\n",
    "\ttext=text_data,\n",
    "\toptimizer=OPTIMIZER,\n",
    "\tdevice=(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\tbatch_size=32,\n",
    "\tmax_batches=None,\n",
    "\tprint_interval=100,\n",
    "\tepochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(MODEL_TRAINED, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " smiled She\n",
      " walked goodbye job\n",
      " As eyebrows meager\n",
      " He They It feeding \n",
      "des\n",
      " ItWhen Heay\n",
      "\n",
      "\n",
      " insidemy\n",
      " He\n",
      "\n",
      " Her too Mom\n",
      " stoppedir She sick extracts go He\n",
      " They\n",
      " Lily\n",
      " rounded Lily\n",
      " Oneony farBen explanandem The exercise\n",
      " August sq help not\" The  would teaspoonDon hearuin's\n",
      " magic Heicy councill They \" She\n",
      "\n",
      " warheads Every She Heâ\n",
      " pod\n",
      "\n",
      " Suddenly foolish\n",
      "\n",
      "phi shop Cer find Lily\n",
      " They DougWhat\n",
      "\n",
      "\n",
      " things They The loud He\n",
      " Her\n",
      " Mr There cheap picnic\n",
      "sale One She\n",
      " They strawberriesSo\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_TRAINED.generate(\"The \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
