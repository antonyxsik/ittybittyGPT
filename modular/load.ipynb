{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting of Trained Model\n",
    "\n",
    "Author: Antony Sikorski\n",
    "\n",
    "In this notebook, we load the model and prompt it like we would any other chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries \n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from jaxtyping import Int, Float\n",
    "import tqdm\n",
    "import transformers\n",
    "import transformer_lens\n",
    "from muutils.misc import shorten_numerical_to_str\n",
    "\n",
    "#imports from files\n",
    "from text_dataset import TextDataset\n",
    "from model import GPTConfig, GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab our trained model (change the path to wherever you choose to save your models):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TRAINED = GPT.read(\"C:/Users/anton/Desktop/Mines/DSCI _575_AdvML/Programming_Project/saved_models/model.zanj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your prompt as a string: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time, Tim climbed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " She The He We She The One The The He He Sus They Tim We hand Inâ One outside  Heâ He He Theâ\n",
      " The mom He� He\n",
      " Fl  The After The The The He The Fl So The house She\n",
      " He Sue\n",
      " The Mom He She The\n",
      "\n",
      "\n",
      "â Tim\n",
      " She \n",
      "\n",
      " He  If The The Let\n",
      "\n",
      " After The You He\n",
      "\n",
      " He He  The M He She From\n",
      "\n",
      " He The The One Theâ Tact He In™\n",
      "\n",
      " Look This  The\n",
      " But\n",
      " She His mom They But\n",
      "  Flâ The Tim   The\n",
      " Quick He\n"
     ]
    }
   ],
   "source": [
    "print(MODEL_TRAINED.generate(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great, but could be much worse.. We'll come back to this and make it actually work. I'm pretty sure the model we are using is just a bit less than the smallest TinyStories model (1M), so I assume we can pull this off. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
